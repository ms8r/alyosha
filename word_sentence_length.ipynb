{
 "metadata": {
  "name": "word_sentence_length"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Calculates average word length (in char) and sentence length (words) for a body of text files and plots result as scatter plot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import nltk\n",
      "from nltk.collocations import BigramCollocationFinder\n",
      "from nltk.metrics import BigramAssocMeasures\n",
      "from itertools import combinations\n",
      "from itertools import permutations\n",
      "import numpy as np\n",
      "from alyosha import reference as REF\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "base_path = 'research/hl_texts'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pattern = r'''(?x)        # set flag to allow verbose regexps\n",
      "        ([A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
      "      | \\w+(-\\w+)*        # words with optional internal hyphens\n",
      "      | \\$?\\d+(\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def avrg_sentence_length(src, max_items=10):\n",
      "    src_path = os.path.join(base_path, src)\n",
      "    fl = sorted([f for f in os.listdir(src_path) if f not in ['result_info']])\n",
      "    fl = fl[:min(max_items, len(fl))]\n",
      "    raw = '\\n'.join([open(os.path.join(src_path, fn), 'r').read() for fn in fl])\n",
      "    raw = raw.translate(None, '\\xe2\\x80\\x9c\\xc2\\x94\\x9d\\x99\\xc3\\xa2')\n",
      "    sens = nltk.sent_tokenize(raw)\n",
      "    lens = [len(nltk.regexp_tokenize(s, pattern)) for s in sens]\n",
      "    return np.average(lens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def long_word_perc(src, min_len=15, max_items=10):\n",
      "    src_path = os.path.join(base_path, src)\n",
      "    fl = sorted([f for f in os.listdir(src_path) if f not in ['result_info']])\n",
      "    fl = fl[:min(max_items, len(fl))]\n",
      "    raw = '\\n'.join([open(os.path.join(src_path, fn), 'r').read() for fn in fl])\n",
      "    raw = raw.translate(None, '\\xe2\\x80\\x9c\\xc2\\x94\\x9d\\x99\\xc3\\xa2')\n",
      "    lens = [len(w) for w in nltk.regexp_tokenize(raw, pattern)]\n",
      "    if not lens:\n",
      "        return 0\n",
      "    else:\n",
      "        return 100 * ((np.array(lens) >= min_len).sum() / float(len(lens)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sources = [v[0] for v in sorted(REF.source_sites.values(), key=lambda t: t[1]) if v[0] in os.listdir(base_path)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sent_lens = [(s, avrg_sentence_length(s)) for s in sources]\n",
      "lwp = [(s, long_word_perc(s, min_len=14)) for s in sources]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = np.array([[lw, sl] for (__, sl), (__, lw) in zip(sent_lens, lwp) if sl > 0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "annos = zip([s.split('.')[0] for s in sources], data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure()\n",
      "ax = fig.add_subplot(1, 1, 1)\n",
      "ax.plot(data[:, 0],data[:, 1], 'bo')\n",
      "for src, (x, y) in annos:\n",
      "    ax.annotate(src, xy=(x, y+0.1), horizontalalignment='center')\n",
      "ax.set_title('Average sentence length vs percentage of long words (> 13 char)')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    }
   ],
   "metadata": {}
  }
 ]
}