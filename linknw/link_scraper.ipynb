{
 "metadata": {
  "name": "link_scraper"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from alyosha import alyosha as al\n",
      "reload(al)\n",
      "from alyosha import reference as REF\n",
      "reload(REF)\n",
      "from itertools import permutations, product\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import time\n",
      "from random import random\n",
      "import logging"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logging.basicConfig(filename='out.log', level=logging.DEBUG)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def link_count(src, dest):\n",
      "    lc = 0\n",
      "    try:\n",
      "        gs = al.GoogleSerp('', **{'site': src, 'link': dest})\n",
      "        lc = gs.resnum if gs.resnum else 0\n",
      "    except al.PageRetrievalError:\n",
      "        logging.debug(\"PageRetrievalError on src=%s, dest=%s\",\n",
      "                      src, dest)\n",
      "        raise\n",
      "    except al.EmptySearchResult:\n",
      "        pass\n",
      "    return lc\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sites = [n[0] for __, n in REF.source_sites.iteritems()]\n",
      "todo = [(s, d) for (s, d) in permutations(sites, 2) if not s == d]\n",
      "rest = todo[:]\n",
      "while rest:\n",
      "    for i, (s, d) in enumerate(todo):\n",
      "        if i > 0:\n",
      "            t = (30 * random()) if (i % 25) else (600 * (1 + random()))\n",
      "            time.sleep(t)\n",
      "        try:\n",
      "            lc = link_count(s, d)\n",
      "        except al.PageRetrievalError:\n",
      "            continue\n",
      "        logging.debug(\"lnk_count %s : %s : %d\", s, d, lc)\n",
      "        rest.remove((s, d))\n",
      "    if rest:\n",
      "        time.sleep(1800)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def strip_domain(site):\n",
      "    return site.replace('.com', '').replace('.org', '').replace('.de', '').replace('.edu', '').replace('net', '')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sort_sites = sorted(REF.source_sites.values(), key=lambda t: t[1])\n",
      "headers = [strip_domain(site) for site, score in sort_sites]\n",
      "lnk_counts = np.zeros((len(headers), len(headers)))\n",
      "dflc = pd.DataFrame(lnk_counts, index=headers, columns=headers)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('ref_count_20140706.dat', 'r') as fo:\n",
      "    for line in fo:\n",
      "        fields = [s.strip() for s in line.split(':')]\n",
      "        dflc[strip_domain(fields[0])][strip_domain(fields[1])] = int(fields[2])\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dflc.sum(axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "townhall              8748\n",
        "foxnews              15606\n",
        "weeklystandard       92054\n",
        "econlib               6165\n",
        "nationalreview       11001\n",
        "hoover                1202\n",
        "ft                   43105\n",
        "wsj                  72842\n",
        "economist            29929\n",
        "lawfareblog           8186\n",
        "fivethirtyeight        230\n",
        "csmonitor             6618\n",
        "factcheck              315\n",
        "theatlantic           7508\n",
        "washingtonpost     1673894\n",
        "nytimes             175787\n",
        "brookings             5640\n",
        "spiegel               2550\n",
        "theguardian         117548\n",
        "slate                15009\n",
        "huffingtonpost      180565\n",
        "msnbc                 3402\n",
        "motherjones          38532\n",
        "dailykos           4232391\n",
        "thenation            16656\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 56
    }
   ],
   "metadata": {}
  }
 ]
}