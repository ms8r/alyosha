{
 "metadata": {
  "name": "collocations_differential_across_sources"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Identifies collocations in a body of text files and lists the differences between sources (e.g. collocation that appear in motherjones.com but *not* in nytimes.com and vice versa)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import nltk\n",
      "from nltk.collocations import BigramCollocationFinder\n",
      "from nltk.metrics import BigramAssocMeasures\n",
      "from itertools import combinations\n",
      "from itertools import permutations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "base_path = 'research/hl_texts'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pattern = r'''(?x)        # set flag to allow verbose regexps\n",
      "        ([A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
      "      | \\w+(-\\w+)*        # words with optional internal hyphens\n",
      "      | \\$?\\d+(\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def wlist_from_src(src, token_pattern, max_items=10):\n",
      "    src_path = os.path.join(base_path, src)\n",
      "    file_list = sorted([fn for fn in os.listdir(src_path) if fn not in ['result_info']])\n",
      "    file_list = file_list[:min(max_items, len(file_list))]\n",
      "    raw = '\\n'.join([open(os.path.join(src_path, fn), 'r').read() for fn in file_list])\n",
      "    return [w.translate(None, '\\xe2\\xc2').lower() for w in nltk.regexp_tokenize(raw, token_pattern) if len(w) > 2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sources = os.listdir(base_path)\n",
      "with open('collos_results', 'w') as fout:\n",
      "    for src_pair in combinations(sources, 2):\n",
      "        collos = {}\n",
      "        for src in src_pair:\n",
      "            bcf = BigramCollocationFinder.from_words(wlist_from_src(src, pattern, max_items=5))\n",
      "            bcf.apply_word_filter(lambda w: nltk.pos_tag([w])[0][1][0] in 'CDIPW')\n",
      "            bcf.apply_freq_filter(5)\n",
      "            collos[src] = bcf.nbest(BigramAssocMeasures.likelihood_ratio, 20)\n",
      "        for s1, s2 in permutations(src_pair):\n",
      "            fout.write(\"%s\\n\" % (79 * '-'))\n",
      "            fout.write(\"%s - %s\\n\" % (s1, s2))\n",
      "            fout.write(\"%s\\n\" % (79 * '-'))\n",
      "            for c in (set(collos[s1]) - set(collos[s2])):\n",
      "                  fout.write(\"%s - %s: %s\\n\" % (s1, s2, ' '.join(c)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}