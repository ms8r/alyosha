{
 "metadata": {
  "name": "tfidf_source_check"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note on sklearn's tf-idf calculation:\n",
      "idf = ln({number of docs + 1}/{number of docs containing t + 1}) + 1\n",
      "\n",
      "The addition of 1 inside the ln argument's nominator and denominator can be supressed by setting the `TfidfTransformer`'s `smooth-idf` argument to `False` (which can result in div by zero though, if t does not occur in any of the docs).\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from nltk.stem import SnowballStemmer\n",
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_wordnet_pos(treebank_tag):\n",
      "    \"\"\"\n",
      "    Utility function for turning the treebank POS tags\n",
      "    returned by `nltk.pos_tag()` into WordNet tags required\n",
      "    by the `WordNettLemmatizer`. Only distinguishes ADJ,\n",
      "    ADV, NOUN and VERB, everything else defaults to NOUN\n",
      "    (the `WordNettLemmatizer` default).\n",
      "    \"\"\"\n",
      "    if treebank_tag.startswith('J'):\n",
      "        return nltk.wordnet.wordnet.ADJ\n",
      "    elif treebank_tag.startswith('V'):\n",
      "        return nltk.wordnet.wordnet.VERB\n",
      "    elif treebank_tag.startswith('N'):\n",
      "        return nltk.wordnet.wordnet.NOUN\n",
      "    elif treebank_tag.startswith('R'):\n",
      "        return nltk.wordnet.wordnet.ADV\n",
      "    else:\n",
      "        return nltk.wordnet.wordnet.NOUN"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wnl = nltk.WordNetLemmatizer()\n",
      "english_stemmer = SnowballStemmer('english')\n",
      "\n",
      "class LemmaTfidfVectorizer(TfidfVectorizer):\n",
      "    def build_analyzer(self):\n",
      "        analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
      "        return lambda doc: (wnl.lemmatize(w, get_wordnet_pos(t)) for w, t in nltk.pos_tag(analyzer(doc)))\n",
      "\n",
      "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
      "    def build_analyzer(self):\n",
      "        analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
      "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))\n",
      "\n",
      "class LemmaCountVectorizer(CountVectorizer):\n",
      "    def build_analyzer(self):\n",
      "        analyzer = super(CountVectorizer, self).build_analyzer()\n",
      "        return lambda doc: (wnl.lemmatize(w, get_wordnet_pos(t)) for w, t in nltk.pos_tag(analyzer(doc)))\n",
      "        \n",
      "class StemmedCountVectorizer(CountVectorizer):\n",
      "    def build_analyzer(self):\n",
      "        analyzer = super(CountVectorizer, self).build_analyzer()\n",
      "        return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "base_path = 'research/hl_texts'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compile full vocabulary:\n",
      "cv = LemmaCountVectorizer(input='filename', ngram_range=(2, 3), stop_words='english')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_list = []\n",
      "for src_dir in os.listdir(base_path):\n",
      "    src_path = os.path.join(base_path, src_dir)\n",
      "    file_list += [os.path.join(src_path, f) for f in os.listdir(src_path) if f not in ['result_info']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train = cv.fit(file_list[:3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw = '\\n'.join([open(f, 'r').read() for f in file_list[:3]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pattern = r'''(?x)        # set flag to allow verbose regexps\n",
      "        ([A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
      "      | \\w+(-\\w+)*        # words with optional internal hyphens\n",
      "      | \\$?\\d+(\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wlist = [w.lower() for w in nltk.regexp_tokenize(raw, pattern) if len(w) > 2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bcf = nltk.collocations.BigramCollocationFinder.from_words(wlist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "csm_path = os.path.join(base_path, 'csmonitor.com')\n",
      "csm_texts = [open(os.path.join(csm_path, fname), 'r').read().decode('utf-8')\n",
      "             for fname in os.listdir(csm_path) \n",
      "             if fname not in ['result_info']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = StemmedTfidfVectorizer(min_df=1, ngram_range=(2, 3), use_idf=True, vocabulary=train.vocabulary_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_train = vectorizer.fit_transform(csm_texts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# other sources:\n",
      "th_path = os.path.join(base_path, 'nationalreview.com')\n",
      "th_texts = [open(os.path.join(th_path, fname), 'r').read().decode('utf-8')\n",
      "            for fname in sorted(os.listdir(th_path))\n",
      "            if fname not in ['result_info']]\n",
      "raw_text = '\\n'.join(th_texts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_th = vectorizer.transform([raw_text])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "th_tfidf = zip(vectorizer.get_feature_names(), x_th.toarray()[-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "th_tfidf.sort(key=lambda k: k[1], reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "th_tfidf[:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "[(u'hobby lobbi', 0.3856322008612712),\n",
        " (u'supreme court', 0.17960951820935919),\n",
        " (u'compelling interest', 0.13360894703155152),\n",
        " (u'birth control', 0.12536832675575224),\n",
        " (u'court decis', 0.090543791545821053),\n",
        " (u'hhs mandat', 0.085729147363169472),\n",
        " (u'little sist', 0.085023875383714601),\n",
        " (u'restrictive mean', 0.085023875383714601),\n",
        " (u'court rul', 0.08437334805144471),\n",
        " (u'religious freedom', 0.076613977461848587),\n",
        " (u'free exercis', 0.074385843942134017),\n",
        " (u'boss busi', 0.071799333279197006),\n",
        " (u'national review', 0.071799333279197006),\n",
        " (u'closely held', 0.06136243494650525),\n",
        " (u'supreme court rul', 0.06136243494650525),\n",
        " (u'female employe', 0.060731339559796156),\n",
        " (u'freedom restor', 0.059392380735484245),\n",
        " (u'freedom restoration act', 0.059392380735484245),\n",
        " (u'religious freedom restor', 0.059392380735484245),\n",
        " (u'restoration act', 0.059392380735484245),\n",
        " (u'family busi', 0.057152764908779644),\n",
        " (u'held corpor', 0.057152764908779644),\n",
        " (u'called accommod', 0.053849499959397751),\n",
        " (u'closely held compani', 0.053849499959397751),\n",
        " (u'closely held corpor', 0.053849499959397751),\n",
        " (u'compelling st', 0.053849499959397751),\n",
        " (u'compelling state interest', 0.053849499959397751),\n",
        " (u'conestoga decis', 0.053849499959397751),\n",
        " (u'held compani', 0.053849499959397751),\n",
        " (u'hobby lobby conestoga', 0.053849499959397751),\n",
        " (u'hobby lobby health', 0.053849499959397751),\n",
        " (u'lobby conestoga', 0.053849499959397751),\n",
        " (u'lobby conestoga decis', 0.053849499959397751),\n",
        " (u'lobby health', 0.053849499959397751),\n",
        " (u'means test', 0.053849499959397751),\n",
        " (u'restrictive means test', 0.053849499959397751),\n",
        " (u'state interest', 0.053849499959397751),\n",
        " (u'ultimate merit', 0.053849499959397751),\n",
        " (u'contraception mand', 0.053692130578192089),\n",
        " (u'supreme court decis', 0.053692130578192089),\n",
        " (u'hobby lobby decis', 0.053132745672952869),\n",
        " (u'lobby decis', 0.053132745672952869),\n",
        " (u'substantial burden', 0.048585071647836917),\n",
        " (u'religious liberti', 0.046021826209878935),\n",
        " (u'birth control pil', 0.042864573681584736),\n",
        " (u'control pil', 0.042864573681584736),\n",
        " (u'obamacare contraception mand', 0.042864573681584736),\n",
        " (u'religious objector', 0.042864573681584736),\n",
        " (u'remain fre', 0.042864573681584736),\n",
        " (u'majority opinion', 0.042506196538362295),\n",
        " (u'obamacare contracept', 0.036438803735877691),\n",
        " (u'provide contracept', 0.036438803735877691),\n",
        " (u'16 kind', 0.035899666639598503),\n",
        " (u'abortifacients steril', 0.035899666639598503),\n",
        " (u'bacon cheeseburg', 0.035899666639598503),\n",
        " (u'carve out', 0.035899666639598503),\n",
        " (u'court held', 0.035899666639598503),\n",
        " (u'court protect', 0.035899666639598503),\n",
        " (u'eleventh circuit', 0.035899666639598503),\n",
        " (u'email protect', 0.035899666639598503),\n",
        " (u'emergency contracept', 0.035899666639598503),\n",
        " (u'employer provid', 0.035899666639598503),\n",
        " (u'employer provided insur', 0.035899666639598503),\n",
        " (u'entire hh', 0.035899666639598503),\n",
        " (u'entire hhs mand', 0.035899666639598503),\n",
        " (u'eternal word', 0.035899666639598503),\n",
        " (u'eternal word televis', 0.035899666639598503),\n",
        " (u'forcing hobbi', 0.035899666639598503),\n",
        " (u'forcing hobby lobbi', 0.035899666639598503),\n",
        " (u'furthering compel', 0.035899666639598503),\n",
        " (u'government regul', 0.035899666639598503),\n",
        " (u'harry reid', 0.035899666639598503),\n",
        " (u'health plan pay', 0.035899666639598503),\n",
        " (u'hobby lobby doesn', 0.035899666639598503),\n",
        " (u'honest convict', 0.035899666639598503),\n",
        " (u'human sacrific', 0.035899666639598503),\n",
        " (u'injunctive ord', 0.035899666639598503),\n",
        " (u'judge pryor', 0.035899666639598503),\n",
        " (u'kill human', 0.035899666639598503),\n",
        " (u'lacks compel', 0.035899666639598503),\n",
        " (u'law nerd', 0.035899666639598503),\n",
        " (u'left lean', 0.035899666639598503),\n",
        " (u'legal counsel', 0.035899666639598503),\n",
        " (u'lobby doesn', 0.035899666639598503),\n",
        " (u'lobby health plan', 0.035899666639598503),\n",
        " (u'long hand', 0.035899666639598503),\n",
        " (u'mandate lack', 0.035899666639598503),\n",
        " (u'mandate lacks compel', 0.035899666639598503),\n",
        " (u'matt bowman', 0.035899666639598503),\n",
        " (u'ms ryan', 0.035899666639598503),\n",
        " (u'national review onlin', 0.035899666639598503),\n",
        " (u'non profit', 0.035899666639598503),\n",
        " (u'plan pay', 0.035899666639598503),\n",
        " (u'provide contraceptive coverag', 0.035899666639598503),\n",
        " (u'provided insur', 0.035899666639598503),\n",
        " (u'provided insurance coverag', 0.035899666639598503),\n",
        " (u'pryor opinion', 0.035899666639598503),\n",
        " (u'remains fre', 0.035899666639598503),\n",
        " (u'review onlin', 0.035899666639598503),\n",
        " (u'schlubby law', 0.035899666639598503)]"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_train.toarray()[-1].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 185,
       "text": [
        "(4801,)"
       ]
      }
     ],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "th_tfidf = zip(vectorizer.get_feature_names(), x_train.toarray()[-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}